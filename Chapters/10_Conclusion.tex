I started my internship without any knowledge about recommender systems. Throughout the internship, I experienced firsthand the major challenges such as sparsity, scalability, cold start, etc., that recommender systems face and observed the mainstream approaches developed to overcome these issues. Moreover, I analyzed the state-of-the-art algorithms designed for recommendation systems with their strengths and weaknesses.

As the next step, we needed to test the performances of the implemented recommenders. During the testing phase, I familiarized myself with different cross-validation types such as Leave-one-out, K-Fold, etc., and applied these methods to determine the performances of the recommender systems I implemented. Furthermore, I acquired profound knowledge about popular evaluation metrics and the situations in which they are preferred. For example, RMSE and MAE are widely-used metrics for datasets containing explicit ratings, while hit rate and map@k, which are especially useful if we care about the order of recommended products, are preferred for datasets with implicit ratings. 

From the technical aspect, as a result of working with Neo4j, I learned the basics, pros, and cons of graph databases. Especially the data visualization feature of Neo4j was really helpful to analyze the dataset. The first versions of the recommenders I implemented were running very slowly due to lots of unnecessary iterations; the solution was performing the operations with a matrix approach using Numpy. This experience showed me the efficiency of Numpy coming from being written based on C. Since one of the recommenders is graph-based, I got to know python libraries with graph utilities such as Scipy and Scikit-learn, which provided information that could also be useful in future projects.

On the whole, the internship has provided me with new insights into recommender systems and, in general, data science. 